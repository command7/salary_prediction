{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data():\n",
    "    def __init__(self, train_csv, train_target_csv, cat_features, num_features, target):\n",
    "        self.cat_features = cat_features\n",
    "        self.num_features = num_features\n",
    "        self.target_label = target\n",
    "        self.data_frame = self.read_data(train_csv, train_target_csv)\n",
    "        self.target_data = None\n",
    "        self.Xtrain = None\n",
    "        self.ytrain = None\n",
    "        self.Xtest = None\n",
    "        self.ytest = None\n",
    "        self.pre_process()\n",
    "        self.split_data()\n",
    "        \n",
    "    def standardize_column_names(self):\n",
    "        old_column_names = self.feature_names\n",
    "        new_column_names = [column_name.lower() for column_name in old_column_names]\n",
    "        self.feature_names = new_column_names\n",
    "        self.data_frame.columns = self.feature_names\n",
    "\n",
    "    def convert_to_cat_dtype(self):\n",
    "        for feat in self.cat_features:\n",
    "            self.data_frame[feat] = self.data_frame[feat].astype(\"category\")\n",
    "    \n",
    "    def scale_numeric_features(self):\n",
    "        num_data = self.data_frame[self.num_features].values\n",
    "        std_scaler = StandardScaler()\n",
    "        scaled_values = std_scaler.fit_transform(num_data)\n",
    "        num_df = pd.DataFrame(scaled_values, columns=self.num_features)\n",
    "        test= pd.concat([num_df, self.data_frame[self.cat_features]], axis=1)\n",
    "        \n",
    "    def encode_cat_features(self):\n",
    "        new_df = self.data_frame[self.num_features].copy()\n",
    "        for cat_feature in self.cat_features:\n",
    "            encoded_output = pd.get_dummies(self.data_frame[cat_feature])\n",
    "            new_df = pd.concat([new_df, encoded_output], axis=1)\n",
    "        self.data_frame = new_df\n",
    "        \n",
    "    def get_target(self):\n",
    "        return self.data_frame.loc[\"salary\"].copy()\n",
    "            \n",
    "    def clean_data(self, df):\n",
    "        total_df = df.copy()\n",
    "        total_df.drop_duplicates(inplace=True)\n",
    "        clean_df = total_df[total_df.salary >0].copy()\n",
    "        return clean_df\n",
    "\n",
    "    def pre_process(self):\n",
    "        self.convert_to_cat_dtype()\n",
    "        self.scale_numeric_features()\n",
    "        self.encode_cat_features()\n",
    "        \n",
    "    def read_data(self, csv1, csv2):\n",
    "        df = pd.read_csv(csv1)\n",
    "        df2 = pd.read_csv(csv2)\n",
    "        total_df = pd.concat([df, df2],axis=1)\n",
    "        clean_df = self.clean_data(total_df)\n",
    "        self.target_data = clean_df[\"salary\"].copy()\n",
    "        return clean_df\n",
    "    \n",
    "    def split_data(self):\n",
    "        consolidated_df = pd.concat([self.data_frame, self.target_data],axis=1)\n",
    "        train, test = train_test_split(consolidated_df, test_size=0.2)\n",
    "        self.Xtrain = train.iloc[:, :-1]\n",
    "        self.ytrain = train.iloc[:,-1]\n",
    "        self.Xtest = test.iloc[:, :-1]\n",
    "        self.ytest = test.iloc[:,-1]\n",
    "\n",
    "\n",
    "class Models:\n",
    "    def __init__(self, data):\n",
    "        self.Xtrain = data.Xtrain\n",
    "        self.ytrain = data.ytrain\n",
    "        self.Xtest = data.Xtest\n",
    "        self.ytest = data.ytest\n",
    "        self.models = []\n",
    "        self.model_info = {}\n",
    "        self.predictions = None\n",
    "        self.best_model = None\n",
    "        \n",
    "    \n",
    "    def add_model(self, model):\n",
    "        self.models.append(model)\n",
    "        \n",
    "    \n",
    "    def cross_validate(self, k):\n",
    "        for model in self.models:\n",
    "            cross_evaluation = cross_val_score(model, self.Xtrain, self.ytrain, cv=k, scoring=\"neg_mean_squared_error\")\n",
    "            score = np.mean(np.negative(cross_evaluation))\n",
    "            self.model_info[model] = score\n",
    "        \n",
    "    def select_best_model(self):\n",
    "        self.best_model = min(self.model_info, key=self.model_info.get)\n",
    "        \n",
    "    def summarize(self):\n",
    "        for model in self.models:\n",
    "            print(model)\n",
    "            print(print(self.model_info[model]))\n",
    "        print(self.best_model)\n",
    "            \n",
    "    def hyper_param_tune(self, model, params):\n",
    "        grid_search = GridSearchCV(model, params, cv=5, scoring = \"neg_mean_squared_error\")\n",
    "        grid_search.fit(self.Xtrain, self.ytrain)\n",
    "        return grid_search\n",
    "        \n",
    "            \n",
    "    def run(self):\n",
    "        self.cross_validate(5)\n",
    "        self.select_best_model()\n",
    "        self.summarize()\n",
    "        \n",
    "            \n",
    "    \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(799996, 93)\n",
      "(199999, 93)\n",
      "(799996,)\n",
      "(199999,)\n"
     ]
    }
   ],
   "source": [
    "dataset_features = \"data/train_features.csv\"\n",
    "dataset_target = \"data/train_salaries.csv\"\n",
    "cat_features = [\"companyId\", \"jobType\", \"degree\", \"major\", \"industry\"]\n",
    "num_features = [\"milesFromMetropolis\", \"yearsExperience\"]\n",
    "\n",
    "lin_alg = LinearRegression()\n",
    "ridge_reg = Ridge()\n",
    "rfr = RandomForestRegressor()\n",
    "gbr = GradientBoostingRegressor()\n",
    "\n",
    "param_grid = [{'n_estimators':[3,10,30], 'max_features':[10,30,40,50,60]},\n",
    "             {\"bootstrap\":[False], 'n_estimators':[3,10], 'max_features':[5,20, 50,80]}]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data = Data(dataset_features, dataset_target,cat_features, num_features, \"salary\")\n",
    "    print(data.Xtrain.shape)\n",
    "    print(data.Xtest.shape)\n",
    "    print(data.ytrain.shape)\n",
    "    print(data.ytest.shape)\n",
    "#     models = Models(data)\n",
    "#     models.add_model(lin_alg)\n",
    "#     models.add_model(ridge_reg)\n",
    "#     models.add_model(rfr)\n",
    "#     models.add_model(gbr)\n",
    "#     models.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(dataset_features)\n",
    "testi = pd.read_csv(dataset_target)\n",
    "testing = pd.concat([test, testi], axis=1)\n",
    "testing[testing.salary<=0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
